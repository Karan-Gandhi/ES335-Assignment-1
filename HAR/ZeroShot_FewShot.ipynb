{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Union\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_classes = [\"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
    "\n",
    "def get_sample_data(path, files_per_activity=-1):\n",
    "    sample_data = []\n",
    "    for activity_class in activity_classes:\n",
    "        subpath = os.path.join(os.path.abspath('..'), path, activity_class)\n",
    "        files = os.listdir(subpath)\n",
    "        num_files = len(files) if files_per_activity == -1 else files_per_activity\n",
    "        for file in range(num_files):\n",
    "            sample_data.append(os.path.join(subpath, files[file]))\n",
    "    return sample_data\n",
    "\n",
    "def load_csv_files(directory, label, add_timestamp=True, add_total_acc=True, trim_data=True):\n",
    "    df_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['subject'] = filename.replace('.csv', '')\n",
    "            # 50 samples per second\n",
    "            # 1 sample takes 1/50 seconds\n",
    "            if add_timestamp:\n",
    "                df['timestamp'] = (df.index + 1) / 50\n",
    "            if add_total_acc:\n",
    "                df['total_acc'] = df['accx'] ** 2 + df['accy'] ** 2 + df['accz'] ** 2\n",
    "            if trim_data:\n",
    "                df_list.append(df.iloc[100:600, :])\n",
    "            else:\n",
    "                df_list.append(df)\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    combined_df['y'] = label\n",
    "    return combined_df\n",
    "\n",
    "def prepare_dataset(path):\n",
    "    train_path = os.path.join(path, \"Train\")\n",
    "    test_path = os.path.join(path, \"Test\")\n",
    "    \n",
    "    train_dfs = pd.concat([load_csv_files(os.path.join(train_path, activity_class), label) for label, activity_class in enumerate(activity_classes)])\n",
    "    test_dfs = pd.concat([load_csv_files(os.path.join(test_path, activity_class), label) for label, activity_class in enumerate(activity_classes)])\n",
    "    \n",
    "    return train_dfs, test_dfs\n",
    "\n",
    "def get_tsfel_features(tsfel_features_path):   \n",
    "    data = pd.DataFrame()\n",
    "    for label, activity_class in enumerate(activity_classes):\n",
    "        folder_path = os.path.join(tsfel_features_path, activity_class)\n",
    "        dfs = load_csv_files(folder_path, label, False, False, False)\n",
    "        data = pd.concat([data, dfs], axis=0, ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "    def __init__(self, data: Union[pd.DataFrame, None], classification: Union[str, None], modify=False, precision=None):\n",
    "        self.data = self.modify_data(data, precision) if modify else data\n",
    "        self.classification = classification\n",
    "        self.text = self.format_data_to_string(self.data)\n",
    "\n",
    "    @staticmethod\n",
    "    def modify_data(data: Union[pd.DataFrame, None], precision=None):\n",
    "        data = data.round(precision if precision is not None else 0) if data is not None else data\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_data_to_string(data: Union[pd.DataFrame, None]) -> str:\n",
    "        if data is not None:\n",
    "            array = data.to_numpy()\n",
    "            array_str = np.array2string(array, separator=',', threshold=np.inf, max_line_width=np.inf)\n",
    "            formatted_str = re.sub(r'[\\[\\]]', '', array_str).replace(' ', '')\n",
    "            return formatted_str\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [activity.title().replace('_', ' ') for activity in activity_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "groq_models = {\"llama-3.1-8b-instant\": \"llama-3.1-8b-instant\", \"llama-3.1-70b-versatile\": \"llama-3.1-70b-versatile\", \"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature data from c:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\Datasets\\UCI HAR Dataset\\train...\n",
      "Loading feature data from c:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\Datasets\\UCI HAR Dataset\\test...\n"
     ]
    }
   ],
   "source": [
    "from GenerateDataset import generate_dataset\n",
    "from MakeHARdataset import X_train, X_test, y_train, y_test\n",
    "\n",
    "def clean_data(folder: str = 'Train'):\n",
    "    dataset_features = generate_dataset(filepath=r\"C:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\Datasets\\UCI HAR Dataset\", folder=folder).columns\n",
    "    features = ['tBodyAcc_mean()_X', 'tBodyAcc_mean()_Y', 'tBodyAcc_mean()_Z', 'tGravityAcc_mean()_X', 'tGravityAcc_mean()_Y', 'tGravityAcc_mean()_Z', 'tBodyGyro_mean()_X', 'tBodyGyro_mean()_Y', 'tBodyGyro_mean()_Z', 'y']\n",
    "\n",
    "    X = X_train if folder != 'Test' else X_test\n",
    "    y = y_train if folder != 'Test' else y_test\n",
    "\n",
    "    dataframes = [pd.DataFrame(dataframe, columns=dataset_features[:-1]).assign(y=label) for dataframe, label in zip(X, y)]\n",
    "    labels = []\n",
    "    np.random.seed = 101\n",
    "    np.random.shuffle(dataframes)\n",
    "\n",
    "    for i in range(len(dataframes)):\n",
    "        labels.append(titles[int(dataframes[i].iloc[0, -1])])\n",
    "        dataframes[i] = dataframes[i][features[:-1]]\n",
    "        dataframes[i] = dataframes[i].iloc[10:20, :]\n",
    "\n",
    "    return dataframes, labels\n",
    "\n",
    "train_dataframes, train_labels = clean_data('Train')\n",
    "test_dataframes, test_labels = clean_data('Test')\n",
    "\n",
    "train_examples = [Example(dataframe, label, True, 3) for dataframe, label in zip(train_dataframes, train_labels)]\n",
    "test_examples = [Example(dataframe, label, True, 3) for dataframe, label in zip(test_dataframes, test_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_api_keys = 12\n",
    "model_name = \"llama-3.1-70b-versatile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_api_key = 1\n",
    "\n",
    "query_str = \"\"\"You are given some values of the following features of a human, in order:\n",
    "1. tBodyAcc-mean()-X: Mean of the body acceleration signal in the X-axis (horizontal movement).\n",
    "2. tBodyAcc-mean()-Y: Mean of the body acceleration signal in the Y-axis (vertical movement).\n",
    "3. tBodyAcc-mean()-Z: Mean of the body acceleration signal in the Z-axis (lateral movement).\n",
    "4. tGravityAcc-mean()-X: Mean of the gravity acceleration signal in the X-axis.\n",
    "5. tGravityAcc-mean()-Y: Mean of the gravity acceleration signal in the Y-axis.\n",
    "6. tGravityAcc-mean()-Z: Mean of the gravity acceleration signal in the Z-axis.\n",
    "7. tBodyGyro_mean()_X: Mean of the body gyro signal in the X-axis.\n",
    "8. tBodyGyro_mean()_Y: Mean of the body gyro signal in the Y-axis.\n",
    "9. tBodyGyro_mean()_Z: Mean of the body gyro signal in the Z-axis.\n",
    "\n",
    "Now classify the below activities into one of these activities: Laying, Sitting, Standing, Walking, Walking Downstairs, Walking Upstairs. Make sure you limit your response for each activity to ONLY your classification, without providing any reasoning or justification for it. If you're not sure, return your best guess:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test_template = \"\"\"\n",
    "=======================================================\n",
    "Activity {activity_number}:\n",
    "\n",
    "{activity}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for cur_example, example in enumerate(test_examples):\n",
    "    query_str += test_template.format(activity_number=cur_example + 1, activity=example.text)\n",
    "\n",
    "response = None\n",
    "while not response:\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=os.environ[f'API_KEY_{cur_api_key}'], temperature=0)\n",
    "        response = llm.invoke(query_str).content.strip()\n",
    "    except:\n",
    "        cur_api_key = (cur_api_key % num_api_keys) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.37%\n"
     ]
    }
   ],
   "source": [
    "classifications = response.split('\\n')[2:]\n",
    "classifications = [classification[classification.index('.')+2:] for classification in classifications]\n",
    "\n",
    "correct = sum(1 if classification == test_labels[i] else 0 for i, classification in enumerate(classifications))\n",
    "total = 54\n",
    "accuracy = correct / total\n",
    "\n",
    "accuracy *= 100\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"You are given some values of the following features of a human, in order:\n",
    "1. tBodyAcc-mean()-X: Mean of the body acceleration signal in the X-axis (horizontal movement).\n",
    "2. tBodyAcc-mean()-Y: Mean of the body acceleration signal in the Y-axis (vertical movement).\n",
    "3. tBodyAcc-mean()-Z: Mean of the body acceleration signal in the Z-axis (lateral movement).\n",
    "4. tGravityAcc-mean()-X: Mean of the gravity acceleration signal in the X-axis.\n",
    "5. tGravityAcc-mean()-Y: Mean of the gravity acceleration signal in the Y-axis.\n",
    "6. tGravityAcc-mean()-Z: Mean of the gravity acceleration signal in the Z-axis.\n",
    "7. tBodyGyro_mean()_X: Mean of the body gyro signal in the X-axis.\n",
    "8. tBodyGyro_mean()_Y: Mean of the body gyro signal in the Y-axis.\n",
    "9. tBodyGyro_mean()_Z: Mean of the body gyro signal in the Z-axis.\n",
    "\n",
    "Your task is to classify the activity into one of the following classes: Laying, Sitting, Standing, Walking, Walking Downstairs, Walking Upstairs.\n",
    "\n",
    "Now classify the below activity. Make sure you limit your response to ONLY your classification, without providing any reasoning or justification for it. If you're not sure, return your best guess:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "cur_example = 0\n",
    "cur_api_key = 1\n",
    "\n",
    "while cur_example < len(test_examples):\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=os.environ[f'API_KEY_{cur_api_key}'], temperature=0)\n",
    "        response = llm.invoke(query_str + test_examples[cur_example].text).content.strip()\n",
    "        print(response)\n",
    "        print(test_examples[cur_example].classification)\n",
    "        print()\n",
    "\n",
    "        if response == test_examples[cur_example].classification:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        cur_example += 1\n",
    "    except:\n",
    "        print(f'API key changed to {cur_api_key % num_api_keys + 1}')\n",
    "        cur_api_key = (cur_api_key % num_api_keys) + 1 \n",
    "\n",
    "accuracy = correct / total\n",
    "accuracy *= 100\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing all tests together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama-3.1-70b-versatile\"\n",
    "cur_api_key = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"You are given some values of the following features of a human, in order:\n",
    "1. tBodyAcc-mean()-X: Mean of the body acceleration signal in the X-axis (horizontal movement).\n",
    "2. tBodyAcc-mean()-Y: Mean of the body acceleration signal in the Y-axis (vertical movement).\n",
    "3. tBodyAcc-mean()-Z: Mean of the body acceleration signal in the Z-axis (lateral movement).\n",
    "4. tGravityAcc-mean()-X: Mean of the gravity acceleration signal in the X-axis.\n",
    "5. tGravityAcc-mean()-Y: Mean of the gravity acceleration signal in the Y-axis.\n",
    "6. tGravityAcc-mean()-Z: Mean of the gravity acceleration signal in the Z-axis.\n",
    "7. tBodyGyro_mean()_X: Mean of the body gyro signal in the X-axis.\n",
    "8. tBodyGyro_mean()_Y: Mean of the body gyro signal in the Y-axis.\n",
    "9. tBodyGyro_mean()_Z: Mean of the body gyro signal in the Z-axis.\n",
    "\n",
    "Your task is to classify the activity into one of the following classes: Laying, Sitting, Standing, Walking, Walking Downstairs, Walking Upstairs.\n",
    "\n",
    "Here are some examples to help you get started:\n",
    "\"\"\"\n",
    "\n",
    "example_template = \"\"\"\n",
    "=======================================================\n",
    "- Activity:\n",
    "{activity}\n",
    "\n",
    "- Classification: {classification}\n",
    "\"\"\"\n",
    "\n",
    "for example in train_examples:\n",
    "    query_str += example_template.format(activity=example.text, classification=example.classification)\n",
    "\n",
    "ending_str = \"\"\"\n",
    "Now classify the below activities. Make sure you limit your response for each activity to ONLY your classification, without providing any reasoning or justification for it. If you're not sure, return your best guess:\n",
    "\"\"\"\n",
    "\n",
    "query_str += ending_str\n",
    "\n",
    "test_template = \"\"\"\n",
    "=======================================================\n",
    "Activity {activity_number}:\n",
    "\n",
    "{activity}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for cur_example, example in enumerate(test_examples):\n",
    "    query_str += test_template.format(activity_number=cur_example + 1, activity=example.text)\n",
    "\n",
    "response = None\n",
    "while not response:\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=os.environ[f'API_KEY_{cur_api_key}'], temperature=0)\n",
    "        response = llm.invoke(query_str).content.strip()\n",
    "    except:\n",
    "        cur_api_key = (cur_api_key % 5) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = response.split('\\n\\n')\n",
    "classifications = [classification[classification.index(':')+2:] for classification in classifications]\n",
    "\n",
    "correct = sum(1 if classification == test_labels[i] else 0 for i, classification in enumerate(classifications))\n",
    "total = 54\n",
    "accuracy = correct / total\n",
    "\n",
    "accuracy *= 100\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing tests one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sitting\n",
      "Laying\n",
      "\n",
      "Sitting\n",
      "Sitting\n",
      "\n",
      "Standing\n",
      "Laying\n",
      "\n",
      "Walking Upstairs\n",
      "Walking Upstairs\n",
      "\n",
      "Walking Downstairs\n",
      "Walking Downstairs\n",
      "\n",
      "Laying\n",
      "Walking\n",
      "\n",
      "Walking\n",
      "Walking\n",
      "\n",
      "Sitting\n",
      "Standing\n",
      "\n",
      "Sitting\n",
      "Sitting\n",
      "\n",
      "Walking\n",
      "Walking\n",
      "\n",
      "Laying\n",
      "Laying\n",
      "\n",
      "Walking Downstairs\n",
      "Walking Downstairs\n",
      "\n",
      "Walking Downstairs\n",
      "Walking Downstairs\n",
      "\n",
      "Laying\n",
      "Walking Downstairs\n",
      "\n",
      "Sitting\n",
      "Laying\n",
      "\n",
      "Laying\n",
      "Walking\n",
      "\n",
      "Sitting\n",
      "Standing\n",
      "\n",
      "Walking Downstairs\n",
      "Laying\n",
      "\n",
      "Sitting\n",
      "Sitting\n",
      "\n",
      "Standing\n",
      "Standing\n",
      "\n",
      "Walking Upstairs\n",
      "Walking Upstairs\n",
      "\n",
      "Sitting\n",
      "Standing\n",
      "\n",
      "Walking\n",
      "Walking Downstairs\n",
      "\n",
      "Sitting\n",
      "Walking Upstairs\n",
      "\n",
      "Walking Upstairs\n",
      "Walking Upstairs\n",
      "\n",
      "Laying\n",
      "Laying\n",
      "\n",
      "Standing\n",
      "Laying\n",
      "\n",
      "Standing\n",
      "Sitting\n",
      "\n",
      "Walking Downstairs\n",
      "Sitting\n",
      "\n",
      "Walking Downstairs\n",
      "Walking Downstairs\n",
      "\n",
      "Walking Downstairs\n",
      "Walking Downstairs\n",
      "\n",
      "Standing\n",
      "Standing\n",
      "\n",
      "Standing\n",
      "Standing\n",
      "\n",
      "Standing\n",
      "Standing\n",
      "\n",
      "Sitting\n",
      "Sitting\n",
      "\n",
      "Walking Downstairs\n",
      "Walking Downstairs\n",
      "\n",
      "Sitting\n",
      "Sitting\n",
      "\n",
      "Walking Upstairs\n",
      "Walking Upstairs\n",
      "\n",
      "Standing\n",
      "Laying\n",
      "\n",
      "Walking\n",
      "Walking\n",
      "\n",
      "Walking\n",
      "Walking Upstairs\n",
      "\n",
      "Standing\n",
      "Standing\n",
      "\n",
      "Standing\n",
      "Standing\n",
      "\n",
      "Walking\n",
      "Walking\n",
      "\n",
      "Walking Upstairs\n",
      "Walking Upstairs\n",
      "\n",
      "Walking\n",
      "Walking Downstairs\n",
      "\n",
      "\n",
      "Walking\n",
      "\n",
      "Sitting\n",
      "Sitting\n",
      "\n",
      "Walking Upstairs\n",
      "Walking Upstairs\n",
      "\n",
      "Walking Upstairs\n",
      "Walking Upstairs\n",
      "\n",
      "Walking\n",
      "Walking\n",
      "\n",
      "Sitting\n",
      "Sitting\n",
      "\n",
      "Laying\n",
      "Laying\n",
      "\n",
      "Walking\n",
      "Walking\n",
      "\n",
      "Accuracy: 64.81%\n"
     ]
    }
   ],
   "source": [
    "query_str = \"\"\"You are given some values of the following features of a human, in order:\n",
    "1. tBodyAcc-mean()-X: Mean of the body acceleration signal in the X-axis (horizontal movement).\n",
    "2. tBodyAcc-mean()-Y: Mean of the body acceleration signal in the Y-axis (vertical movement).\n",
    "3. tBodyAcc-mean()-Z: Mean of the body acceleration signal in the Z-axis (lateral movement).\n",
    "4. tGravityAcc-mean()-X: Mean of the gravity acceleration signal in the X-axis.\n",
    "5. tGravityAcc-mean()-Y: Mean of the gravity acceleration signal in the Y-axis.\n",
    "6. tGravityAcc-mean()-Z: Mean of the gravity acceleration signal in the Z-axis.\n",
    "7. tBodyGyro_mean()_X: Mean of the body gyro signal in the X-axis.\n",
    "8. tBodyGyro_mean()_Y: Mean of the body gyro signal in the Y-axis.\n",
    "9. tBodyGyro_mean()_Z: Mean of the body gyro signal in the Z-axis.\n",
    "\n",
    "Your task is to classify the activity into one of the following classes: Laying, Sitting, Standing, Walking, Walking Downstairs, Walking Upstairs.\n",
    "\n",
    "Here are some examples to help you get started:\n",
    "\"\"\"\n",
    "\n",
    "example_template = \"\"\"\n",
    "=======================================================\n",
    "- Activity:\n",
    "{activity}\n",
    "\n",
    "- Classification: {classification}\n",
    "\"\"\"\n",
    "\n",
    "for example in train_examples:\n",
    "    query_str += example_template.format(activity=example.text, classification=example.classification)\n",
    "\n",
    "ending_str = \"\"\"\n",
    "Now classify the below activity. Make sure you limit your response to ONLY your classification, without providing any reasoning or justification for it. If you're not sure, return your best guess. Also, do not add any punctuations. Limit your response to the exact classification and nothing else:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_str += ending_str\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "cur_example = 0\n",
    "cur_api_key = 1\n",
    "\n",
    "while cur_example < len(test_examples):\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=os.environ[f'API_KEY_{cur_api_key}'], temperature=0)\n",
    "        response = llm.invoke(query_str + test_examples[cur_example].text).content.strip()\n",
    "        print(response)\n",
    "        print(test_examples[cur_example].classification)\n",
    "        print()\n",
    "\n",
    "        if response == test_examples[cur_example].classification:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        cur_example += 1\n",
    "    except:\n",
    "        cur_api_key = (cur_api_key % num_api_keys) + 1 \n",
    "\n",
    "accuracy = correct / total\n",
    "accuracy *= 100\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier: 69.44%\n",
      "\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Laying       0.49      0.53      0.51        90\n",
      "           Sitting       0.54      0.58      0.56        90\n",
      "          Standing       0.53      0.43      0.48        90\n",
      "           Walking       0.92      0.84      0.88        90\n",
      "Walking Downstairs       0.71      0.78      0.74        90\n",
      "  Walking Upstairs       1.00      1.00      1.00        90\n",
      "\n",
      "          accuracy                           0.69       540\n",
      "         macro avg       0.70      0.69      0.69       540\n",
      "      weighted avg       0.70      0.69      0.69       540\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[48 19 12  1 10  0]\n",
      " [15 52 21  0  2  0]\n",
      " [23 22 39  2  4  0]\n",
      " [ 1  0  0 76 13  0]\n",
      " [11  4  1  4 70  0]\n",
      " [ 0  0  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "expanded_train_labels = []\n",
    "for df, label in zip(train_dataframes, train_labels):\n",
    "    expanded_train_labels.extend([label] * len(df))\n",
    "\n",
    "expanded_test_labels = []\n",
    "for df, label in zip(test_dataframes, test_labels):\n",
    "    expanded_test_labels.extend([label] * len(df))\n",
    "\n",
    "X_train = pd.concat(train_dataframes, axis=0, ignore_index=True)\n",
    "y_train = pd.Series(expanded_train_labels).reset_index(drop=True)\n",
    "\n",
    "X_test = pd.concat(test_dataframes, axis=0, ignore_index=True)\n",
    "y_test = pd.Series(expanded_test_labels).reset_index(drop=True)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "print(f\"Accuracy of Decision Tree Classifier: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What are the limitations of Zero-Shot Learning and Few-Shot Learning in the context of classifying human activities based on featurized accelerometer data?\n",
    "\n",
    "There are many limitations of using Large Language Models (LLMs) in general, especially for tasks such as classifying human activities based on featureized accelerometer data. The following are some common issues:\n",
    "\n",
    "- **Pretrained knowledge**: These approaches rely heavily on pretrained knowledge to generate new tokens. While Few-Shot Learning is capable of \"learning\" from new context, it still does not perform well on niche, domain-specific tasks like human activity classification with featurized accelerometer data due to the lack of such examples in training. This is why models are first fine-tuned on custom datasets beforehand for tasks like this. This also helps eliminate the inherent bias associated with the task in the already existing model.\n",
    "\n",
    "- **Scalability**: The scalability of using LLMs for classification tasks like this is bottlenecked by the context window of the LLM. In our case, Groq primarily has LLMs with a context window of size 8192. Mixtral had a slightly more generous limit of 32,768 tokens. Fortunately, Meta's new LLM - Llama 3.1 had the largest context window of 131,072 tokens. This turned out to be very useful in our case, especially for Few-Shot learning, as we could pass in more examples. However, using more tokens increases the time taken to process a prompt. \n",
    "\n",
    "- **Use Case**: LLMs are excellent in capturing semantic relationships between text. However, they might not perform as expected in tasks such as ours. One particularly famous and recent example is the question \"Which number is greater: 9.9 or 9.11?\" Llama 3 answered 9.11 which is incorrect. One probable reason for this is that numbers like 9.9 and 9.11 occur frequently in sites like GitHub and denote version numbers, and indeed, 9.11 is greater than 9.9 in such cases. Such results depend on the tokenizer used by the LLM. Llama 3's tokenizer treats \"11\" and \"9\" as single tokens, so it makes sense to say that 9.11 is greater than 9.9. This makes the approach of using LLMs ill-suited for our task as we work with data that is time-series, highly featurized, and very numerical.\n",
    "\n",
    "Now for comparing the limitations of Zero-Shot Learning and Few-Shot Learning:\n",
    "\n",
    "- **Zero-Shot Learning**\n",
    "1. It performs poorly when the activities are dissimilar from the pretrained training data of the model or when the features lack any meanigful semantic relationship, like in the case of featurized accelerometer data.\n",
    "2. It often results in lower accuracy when compared to fully supervised methods. This can be demonstrated empirically as well by confirming that Few-Shot Learning and decision tree performed much better than it.\n",
    "\n",
    "- **Few-Shot Learning**\n",
    "1. Few-Shot learning methods can often lead to overfitting. While experimenting, we found that it incorrectly predicted 100% of values correctly because we did not shuffle the data. We suspect that it was because we gave the data in order: Laying, Sitting, Standing, Walking, Walking Downstairs, Walking Upstairs repeatedly.\n",
    "2. While passing many examples may aid the model in capturing more information, it uses many tokens. We were forced to use the model with the highest context window of 131,072 tokens to fit in all the examples. This is computationally expensive, both, in terms of cost and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. What does the model classify when given input from an entirely new activity that it hasn't seen before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove each feature and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current removed activity is: Laying\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Walking               44.444444\n",
       "Sitting               22.222222\n",
       "Walking Downstairs    22.222222\n",
       "Standing              11.111111\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current removed activity is: Sitting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Standing              33.333333\n",
       "Walking               22.222222\n",
       "Laying                22.222222\n",
       "Walking Downstairs    11.111111\n",
       "Walking Upstairs      11.111111\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current removed activity is: Standing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Walking               44.444444\n",
       "Sitting               33.333333\n",
       "Walking Downstairs    11.111111\n",
       "Laying                11.111111\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current removed activity is: Walking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Standing              44.444444\n",
       "Walking Downstairs    22.222222\n",
       "Walking Upstairs      22.222222\n",
       "Sitting               11.111111\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current removed activity is: Walking Upstairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Standing    33.333333\n",
       "Sitting     33.333333\n",
       "Laying      22.222222\n",
       "Walking     11.111111\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current removed activity is: Walking Downstairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Standing    55.555556\n",
       "Walking     22.222222\n",
       "Sitting     22.222222\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_api_key = 9\n",
    "\n",
    "query_str = \"\"\"You are given some values of the following features of a human, in order:\n",
    "1. tBodyAcc-mean()-X: Mean of the body acceleration signal in the X-axis (horizontal movement).\n",
    "2. tBodyAcc-mean()-Y: Mean of the body acceleration signal in the Y-axis (vertical movement).\n",
    "3. tBodyAcc-mean()-Z: Mean of the body acceleration signal in the Z-axis (lateral movement).\n",
    "4. tGravityAcc-mean()-X: Mean of the gravity acceleration signal in the X-axis.\n",
    "5. tGravityAcc-mean()-Y: Mean of the gravity acceleration signal in the Y-axis.\n",
    "6. tGravityAcc-mean()-Z: Mean of the gravity acceleration signal in the Z-axis.\n",
    "7. tBodyGyro_mean()_X: Mean of the body gyro signal in the X-axis.\n",
    "8. tBodyGyro_mean()_Y: Mean of the body gyro signal in the Y-axis.\n",
    "9. tBodyGyro_mean()_Z: Mean of the body gyro signal in the Z-axis.\n",
    "\n",
    "Now classify the below activities into one of these activities: {activities}. Make sure you limit your response for each activity to ONLY your classification, without providing any reasoning or justification for it. If you're not sure, return your best guess:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test_template = \"\"\"\n",
    "=======================================================\n",
    "Activity {activity_number}:\n",
    "\n",
    "{activity}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "activity_list = ['Laying', 'Sitting', 'Standing', 'Walking', 'Walking Upstairs', 'Walking Downstairs']\n",
    "for activity in activity_list:\n",
    "    temp_activity_list = activity_list.copy()\n",
    "    temp_activity_list.remove(activity)\n",
    "    s = ', '.join(temp_activity_list)\n",
    "    temp_query_str = query_str.format(activities=s)\n",
    "    temp_test_examples = []\n",
    "    for example in test_examples:\n",
    "        if example.classification == activity:\n",
    "            temp_test_examples.append(example)\n",
    "    print(f'Current removed activity is: {activity}')\n",
    "\n",
    "    for cur_example, example in enumerate(temp_test_examples):\n",
    "        temp_query_str += test_template.format(activity_number=cur_example + 1, activity=example.text)\n",
    "\n",
    "    response = None\n",
    "    while not response:\n",
    "        try:\n",
    "            llm = ChatGroq(model=groq_models[model_name], api_key=os.environ[f'API_KEY_{cur_api_key}'], temperature=0)\n",
    "            response = llm.invoke(temp_query_str).content.strip()\n",
    "        except:\n",
    "            cur_api_key = (cur_api_key % num_api_keys) + 1\n",
    "\n",
    "    response = response.split('\\n')\n",
    "    response = [activity_[max(activity_.index(':') if ':' in activity_ else -1, activity_.index('.') if '.' in activity_ else -1)+2:] for activity_ in response]\n",
    "    response = pd.Series(response).value_counts(normalize=True) * 100\n",
    "    display(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test the model with random data (ensuring the data has the same dimensions and range as the previous input) and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = []\n",
    "np.random.seed = 101\n",
    "\n",
    "for i in range(30):\n",
    "    df = pd.DataFrame(np.random.uniform(low=-1, high=1, size=(10, 9)), columns=['tBodyAcc_mean()_X', 'tBodyAcc_mean()_Y', 'tBodyAcc_mean()_Z', 'tGravityAcc_mean()_X', 'tGravityAcc_mean()_Y', 'tGravityAcc_mean()_Z', 'tBodyGyro_mean()_X', 'tBodyGyro_mean()_Y', 'tBodyGyro_mean()_Z'])\n",
    "    random_data.append(Example(df, None, True, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with zero-shot learning\n",
    "cur_api_key = 8\n",
    "model_name = \"llama-3.1-70b-versatile\"\n",
    "\n",
    "query_str = \"\"\"You are given some values of the following features of a human, in order:\n",
    "1. tBodyAcc-mean()-X: Mean of the body acceleration signal in the X-axis (horizontal movement).\n",
    "2. tBodyAcc-mean()-Y: Mean of the body acceleration signal in the Y-axis (vertical movement).\n",
    "3. tBodyAcc-mean()-Z: Mean of the body acceleration signal in the Z-axis (lateral movement).\n",
    "4. tGravityAcc-mean()-X: Mean of the gravity acceleration signal in the X-axis.\n",
    "5. tGravityAcc-mean()-Y: Mean of the gravity acceleration signal in the Y-axis.\n",
    "6. tGravityAcc-mean()-Z: Mean of the gravity acceleration signal in the Z-axis.\n",
    "7. tBodyGyro_mean()_X: Mean of the body gyro signal in the X-axis.\n",
    "8. tBodyGyro_mean()_Y: Mean of the body gyro signal in the Y-axis.\n",
    "9. tBodyGyro_mean()_Z: Mean of the body gyro signal in the Z-axis.\n",
    "\n",
    "Now classify the below activities into one of these activities: Laying, Sitting, Standing, Walking, Walking Downstairs, Walking Upstairs. Make sure you limit your response for each activity to ONLY your classification, without providing any reasoning or justification for it. If you're not sure, return your best guess:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test_template = \"\"\"\n",
    "=======================================================\n",
    "Activity {activity_number}:\n",
    "\n",
    "{activity}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for cur_example, example in enumerate(random_data):\n",
    "    query_str += test_template.format(activity_number=cur_example+1, activity=example.text)\n",
    "\n",
    "response = None\n",
    "while not response:\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=os.environ[f'API_KEY_{cur_api_key}'], temperature=0)\n",
    "        response = llm.invoke(query_str).content.strip()\n",
    "    except:\n",
    "        cur_api_key = (cur_api_key % num_api_keys) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage-wise Distribution of Activities\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Walking               31.666667\n",
       "Sitting               18.333333\n",
       "Standing              18.333333\n",
       "Walking Downstairs    11.666667\n",
       "Walking Upstairs      11.666667\n",
       "Laying                 8.333333\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifications = [classification[classification.index(':')+2:] for classification in response.split('\\n')]\n",
    "classifications = pd.Series(classifications)\n",
    "classifications = classifications.value_counts(normalize=True) * 100\n",
    "print(f'Percentage-wise Distribution of Activities')\n",
    "display(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"You are given some values of the following features of a human, in order:\n",
    "1. tBodyAcc-mean()-X: Mean of the body acceleration signal in the X-axis (horizontal movement).\n",
    "2. tBodyAcc-mean()-Y: Mean of the body acceleration signal in the Y-axis (vertical movement).\n",
    "3. tBodyAcc-mean()-Z: Mean of the body acceleration signal in the Z-axis (lateral movement).\n",
    "4. tGravityAcc-mean()-X: Mean of the gravity acceleration signal in the X-axis.\n",
    "5. tGravityAcc-mean()-Y: Mean of the gravity acceleration signal in the Y-axis.\n",
    "6. tGravityAcc-mean()-Z: Mean of the gravity acceleration signal in the Z-axis.\n",
    "7. tBodyGyro_mean()_X: Mean of the body gyro signal in the X-axis.\n",
    "8. tBodyGyro_mean()_Y: Mean of the body gyro signal in the Y-axis.\n",
    "9. tBodyGyro_mean()_Z: Mean of the body gyro signal in the Z-axis.\n",
    "\n",
    "Your task is to classify the activity into one of the following classes: Laying, Sitting, Standing, Walking, Walking Downstairs, Walking Upstairs.\n",
    "\n",
    "Here are some examples to help you get started:\n",
    "\"\"\"\n",
    "\n",
    "example_template = \"\"\"\n",
    "=======================================================\n",
    "- Activity:\n",
    "{activity}\n",
    "\n",
    "- Classification: {classification}\n",
    "\"\"\"\n",
    "\n",
    "for example in train_examples[::2]:\n",
    "    query_str += example_template.format(activity=example.text, classification=example.classification)\n",
    "\n",
    "for example in train_examples[1::2]:\n",
    "    query_str += example_template.format(activity=example.text, classification=example.classification)\n",
    "\n",
    "ending_str = \"\"\"\n",
    "Now classify the below activity. Make sure you limit your response to ONLY your classification, without providing any reasoning or justification for it. If you're not sure, return your best guess. Also, do not add any punctuations. Limit your response to the exact classification and nothing else:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_str += ending_str\n",
    "\n",
    "responses = []\n",
    "cur_example = 0\n",
    "cur_api_key = 9\n",
    "\n",
    "while cur_example < len(random_data):\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=os.environ[f'API_KEY_{cur_api_key}'], temperature=0)\n",
    "        response = llm.invoke(query_str + random_data[cur_example].text).content.strip()\n",
    "        responses.append(response)\n",
    "\n",
    "        cur_example += 1\n",
    "    except:\n",
    "        cur_api_key = (cur_api_key % num_api_keys) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Walking             0.666667\n",
       "Walking Upstairs    0.233333\n",
       "Sitting             0.066667\n",
       "                    0.033333\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = pd.Series(responses)\n",
    "responses = responses.value_counts(normalize=True)\n",
    "responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
