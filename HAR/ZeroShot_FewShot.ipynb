{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Union\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from GenerateDataset import generate_dataset\n",
    "import numpy as np\n",
    "import re\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_classes = [\"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
    "\n",
    "def get_sample_data(path, files_per_activity=-1):\n",
    "    sample_data = []\n",
    "    for activity_class in activity_classes:\n",
    "        subpath = os.path.join(os.path.abspath('..'), path, activity_class)\n",
    "        files = os.listdir(subpath)\n",
    "        num_files = len(files) if files_per_activity == -1 else files_per_activity\n",
    "        for file in range(num_files):\n",
    "            sample_data.append(os.path.join(subpath, files[file]))\n",
    "    return sample_data\n",
    "\n",
    "def load_csv_files(directory, label, add_timestamp=True, add_total_acc=True, trim_data=True):\n",
    "    df_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['subject'] = filename.replace('.csv', '')\n",
    "            # 50 samples per second\n",
    "            # 1 sample takes 1/50 seconds\n",
    "            if add_timestamp:\n",
    "                df['timestamp'] = (df.index + 1) / 50\n",
    "            if add_total_acc:\n",
    "                df['total_acc'] = df['accx'] ** 2 + df['accy'] ** 2 + df['accz'] ** 2\n",
    "            if trim_data:\n",
    "                df_list.append(df.iloc[100:600, :])\n",
    "            else:\n",
    "                df_list.append(df)\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    combined_df['y'] = label\n",
    "    return combined_df\n",
    "\n",
    "def prepare_dataset(path):\n",
    "    train_path = os.path.join(path, \"Train\")\n",
    "    test_path = os.path.join(path, \"Test\")\n",
    "    \n",
    "    train_dfs = pd.concat([load_csv_files(os.path.join(train_path, activity_class), label) for label, activity_class in enumerate(activity_classes)])\n",
    "    test_dfs = pd.concat([load_csv_files(os.path.join(test_path, activity_class), label) for label, activity_class in enumerate(activity_classes)])\n",
    "    \n",
    "    return train_dfs, test_dfs\n",
    "\n",
    "def get_tsfel_features(tsfel_features_path):   \n",
    "    data = pd.DataFrame()\n",
    "    for label, activity_class in enumerate(activity_classes):\n",
    "        folder_path = os.path.join(tsfel_features_path, activity_class)\n",
    "        dfs = load_csv_files(folder_path, label, False, False, False)\n",
    "        data = pd.concat([data, dfs], axis=0, ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = get_sample_data(os.path.join(\"Datasets\", 'Combined', 'Train'))\n",
    "sample_data.extend(get_sample_data(os.path.join(\"Datasets\", 'Combined', 'Test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "\n",
    "    def __init__(self, data: Union[pd.DataFrame, None], explanation: Union[str, None], classification: Union[str, None], modify=False, precision=None):\n",
    "        self.data = self.modify_data(data, precision) if modify else data\n",
    "        self.explanation = explanation\n",
    "        self.classification = classification\n",
    "        self.text = re.sub(r'[\\[\\]]', '', np.array2string(self.data.to_numpy(), separator=',')).replace(' ', '')\n",
    "\n",
    "    @staticmethod\n",
    "    def modify_data(data: Union[pd.DataFrame, None], precision=None):\n",
    "        data = data.round(precision if precision is not None else 0) if data is not None else data\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(sample_data[i]).iloc[100:600, :] for i in range(len(sample_data))]\n",
    "titles = [sample.split('\\\\')[-2].title().replace('_', ' ') for sample in sample_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # load environment variables\n",
    "Groq_Token = os.environ['API_KEY']\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE : DO NOT SHARE THE API KEY WITH ANYONE. DO NOT COMMIT THE API KEY TO GITHUB.**\n",
    "\n",
    "Always do a sanity check before committing the code to github. If the key is found in the code, you will be penalized with a 0.5 marks deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity 1: Sitting\n",
      "Activity 2: Walking\n",
      "Activity 3: Standing\n",
      "Activity 4: Walking Downstairs\n",
      "Activity 5: Walking Upstairs\n",
      "Activity 6: Laying\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    examples.append(Example(df.iloc[200:300], None, titles[i], True, 3))\n",
    "\n",
    "query = \"\"\"\n",
    "You are given the x, y and z values of acceleration of a person. You need to classify the activities into one of the following classes: Laying, Sitting, Standing, Walking, Walking downstairs, Walking Upstairs.\n",
    "Analyze the data carefully. Of course, in stationary activities like laying, sitting, and standing, there is not much change in their values. However, for dynamic activities like walking, some of their values change a lot.\n",
    "Think in the following process:\n",
    "- First determine whether it is a stationary activity or a dynamic activity. You can do this by observing if the change in each coordinate is minimal or a lot.\n",
    "- If the activity is stationary: for sitting, the y and z components are nearly identical. For laying, the x component is lower than the y and z components, and for standing, the x component is higher than the y and z components. \n",
    "- If the activity is dynamic (walking): determine the activity based on observation.\n",
    "Each activity consists of 100 rows equivalent to 2 seconds of that activity. Output your best guess without any explanation. Your response for each activity will therefore consist of at most two words.\n",
    "\"\"\"\n",
    "\n",
    "for i, example in enumerate(examples):\n",
    "    query += f\"\\n\\n## Activity {i + 1}\\n\\n{example.text}\"\n",
    "\n",
    "model_name = \"mixtral\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "print(llm.invoke(query).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m (correct \u001b[38;5;241m/\u001b[39m total) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main(examples)\n",
      "Cell \u001b[1;32mIn[13], line 32\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m     29\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     31\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [process_example(ex) \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[1;32m---> 32\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks) \n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response, classification \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, classification)\n",
      "Cell \u001b[1;32mIn[13], line 24\u001b[0m, in \u001b[0;36mprocess_example\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_example\u001b[39m(example: Example):\n\u001b[1;32m---> 24\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mainvoke(query\u001b[38;5;241m.\u001b[39mformat(text\u001b[38;5;241m=\u001b[39mexample\u001b[38;5;241m.\u001b[39mtext))\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip(), example\u001b[38;5;241m.\u001b[39mclassification\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:297\u001b[0m, in \u001b[0;36mBaseChatModel.ainvoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    295\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    296\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 297\u001b[0m     llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[0;32m    298\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    299\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    300\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    301\u001b[0m         tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    302\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    303\u001b[0m         run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    304\u001b[0m         run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    306\u001b[0m     )\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ChatGeneration, llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[0;32m    787\u001b[0m         prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    788\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:746\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    734\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m    735\u001b[0m             \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m    736\u001b[0m                 run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    744\u001b[0m             ]\n\u001b[0;32m    745\u001b[0m         )\n\u001b[1;32m--> 746\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    747\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    748\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item, union-attr]\u001b[39;00m\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    750\u001b[0m ]\n\u001b[0;32m    751\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:922\u001b[0m, in \u001b[0;36mBaseChatModel._agenerate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 922\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[0;32m    923\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    924\u001b[0m         )\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    926\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:493\u001b[0m, in \u001b[0;36mChatGroq._agenerate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    489\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    492\u001b[0m }\n\u001b[1;32m--> 493\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:578\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    467\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[0;32m    468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/openai/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    580\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[0;32m    581\u001b[0m             {\n\u001b[0;32m    582\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    584\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    585\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    586\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    587\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    589\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    590\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    591\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    592\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    593\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    594\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    595\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    596\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    597\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    598\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    599\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    600\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    601\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    602\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    603\u001b[0m             },\n\u001b[0;32m    604\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    605\u001b[0m         ),\n\u001b[0;32m    606\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    607\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    608\u001b[0m         ),\n\u001b[0;32m    609\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    610\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    611\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[0;32m    612\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\groq\\_base_client.py:1762\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1750\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1758\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[0;32m   1759\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1760\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1761\u001b[0m     )\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\groq\\_base_client.py:1478\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1471\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1476\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1477\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m-> 1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1479\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1480\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1481\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1482\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1483\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m   1484\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Nishchay\\Desktop\\College\\ES 335 Machine Learning\\Assignments\\es335-24-fall-assignment-1\\venv\\Lib\\site-packages\\groq\\_base_client.py:1569\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1566\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maread()\n\u001b[0;32m   1568\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1572\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1573\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1576\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1577\u001b[0m )\n",
      "\u001b[1;31mInternalServerError\u001b[0m: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}"
     ]
    }
   ],
   "source": [
    "\n",
    "examples = []\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    examples.append(Example(df.iloc[100:400], None, titles[i], True, None))\n",
    "\n",
    "query = \"\"\"\n",
    "You are given the x, y and z values of acceleration of a person. You need to classify the activity into one of the following classes: Laying, Sitting, Standing, Walking, Walking downstairs, Walking Upstairs.\n",
    "Analyze the data carefully. Of course, in stationary activities like laying, sitting, and standing, there is not much change in their values. However, for dynamic activities like walking, some of their values change a lot.\n",
    "\n",
    "Think in the following process:\n",
    "- First determine whether it is a stationary activity or a dynamic activity. You can do this by observing if the change in each coordinate is minimal (if the maximum value minus the minimal value is less than 0.1 for that component, then it is very little, it means it is most probable that there was no movement involved) or a lot.\n",
    "- If the activity is stationary: for sitting, the y and z components are nearly identical (if the maximum value minus the minimal value is less than 0.1 for each of these components, then they are identical). For laying, the maximum x component is lower than the maximum y component by at least 0.1. For standing, the maximum x component is greater than the maximum y component by at least 0.1\n",
    "- If the activity is dynamic (walking): determine the activity based on observation.\n",
    "\n",
    "The activity consists of 300 rows equivalent to 6 seconds of that activity. Output your best guess without any explanation. Your response the activity will therefore consist of at most two words.\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "model_name = \"gemma-9b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "\n",
    "async def process_example(example: Example):\n",
    "    response = await llm.ainvoke(query.format(text=example.text))\n",
    "    return response.content.strip(), example.classification\n",
    "\n",
    "async def main(examples: list):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    tasks = [process_example(ex) for ex in examples]\n",
    "    results = await asyncio.gather(*tasks) \n",
    "\n",
    "    for response, classification in results:\n",
    "        print(response, \"|\", classification)\n",
    "        if response == classification:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "await main(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Standing | Laying\n",
      "Laying | Laying\n",
      "Sitting | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Standing | Laying\n",
      "Standing | Laying\n",
      "Sitting | Laying\n",
      "Sitting | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Sitting | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Sitting | Laying\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Standing | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Standing | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Standing | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Sitting | Sitting\n",
      "Standing | Sitting\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Walking | Walking\n",
      "Standing | Walking\n",
      "Sitting | Walking\n",
      "Sitting | Walking\n",
      "Sitting | Walking\n",
      "Walking Downstairs | Walking\n",
      "Walking | Walking\n",
      "Sitting | Walking\n",
      "Walking Downstairs | Walking\n",
      "Walking Downstairs | Walking\n",
      "Walking | Walking\n",
      "Standing | Walking\n",
      "Standing | Walking\n",
      "Sitting | Walking\n",
      "Standing | Walking\n",
      "Sitting | Walking\n",
      "Walking | Walking\n",
      "Sitting | Walking\n",
      "Walking | Walking\n",
      "Walking Downstairs | Walking\n",
      "Walking | Walking\n",
      "Sitting | Walking Downstairs\n",
      "Sitting | Walking Downstairs\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Walking | Walking Downstairs\n",
      "Sitting | Walking Downstairs\n",
      "Walking | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Walking | Walking Downstairs\n",
      "Walking | Walking Downstairs\n",
      "Sitting | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Sitting | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Walking | Walking Downstairs\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Walking | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Walking Downstairs | Walking Upstairs\n",
      "Walking Downstairs | Walking Upstairs\n",
      "Sitting | Walking Upstairs\n",
      "Walking Downstairs | Walking Upstairs\n",
      "Standing | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Walking Downstairs | Walking Upstairs\n",
      "Walking Downstairs | Walking Upstairs\n",
      "Laying | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Sitting | Walking Upstairs\n",
      "Sitting | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Standing | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Standing | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Sitting | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Standing | Laying\n",
      "Laying | Laying\n",
      "Sitting | Laying\n",
      "Sitting | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Laying | Laying\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Sitting\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Laying | Standing\n",
      "Standing | Walking\n",
      "Standing | Walking\n",
      "Sitting | Walking\n",
      "Sitting | Walking\n",
      "Sitting | Walking\n",
      "Sitting | Walking\n",
      "Walking | Walking\n",
      "Standing | Walking\n",
      "Sitting | Walking\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Walking | Walking Downstairs\n",
      "Walking | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Standing | Walking Downstairs\n",
      "Walking Downstairs | Walking Downstairs\n",
      "Walking | Walking Upstairs\n",
      "Sitting | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Standing | Walking Upstairs\n",
      "Walking | Walking Upstairs\n",
      "Walking Downstairs | Walking Upstairs\n",
      "Sitting | Walking Upstairs\n",
      "Sitting | Walking Upstairs\n",
      "Laying | Walking Upstairs\n",
      "Accuracy: 20.00%\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    examples.append(Example(df.iloc[100:400], None, titles[i], True, None))\n",
    "\n",
    "query = \"\"\"\n",
    "You are given the x, y and z values of acceleration of a person. You need to classify the activity into one of the following classes: Laying, Sitting, Standing, Walking, Walking Downstairs, Walking Upstairs.\n",
    "Analyze the data carefully. Of course, in stationary activities like laying, sitting, and standing, there is not much change in their values. However, for dynamic activities like walking, some of their values change a lot.\n",
    "\n",
    "Think in the following process:\n",
    "- First determine whether it is a stationary activity or a dynamic activity. You can do this by observing if the change in each coordinate is minimal (if the maximum value minus the minimal value is less than 0.1 for that component, then it is very little, it means it is most probable that there was no movement involved) or a lot.\n",
    "- If the activity is stationary: for sitting, the y and z components are nearly identical (if the maximum value minus the minimal value is less than 0.1 for each of these components, then they are identical). For laying, the maximum x component is lower than the maximum y component by at least 0.1. For standing, the maximum x component is greater than the maximum y component by at least 0.1\n",
    "- If the activity is dynamic (walking): determine the activity based on observation.\n",
    "\n",
    "The activity consists of 300 rows equivalent to 6 seconds of that activity. Output your best guess without any explanation. Your response the activity will therefore consist of at most two words.\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "model_name = \"gemma-9b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for example in examples:\n",
    "    response = llm.invoke(query.format(text=example.text)).content.strip()\n",
    "    print(response, \"|\" ,example.classification)\n",
    "    if response == example.classification:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "accuracy *= 100\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass examples in the prompt, we need a high context window. For this task, we will use mixtral (mixtral-8x7b-32768). For each activity, if we were to take 1 subject's data with 500 time stamps, the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n",
      "\n",
      "Explanation: Although the sentence mentions a negative aspect (\"the delivery was delayed\"), the positive sentiments expressed in the sentence (\"The product quality is amazing\" and \"I am happy with the customer service\") outweigh the negative one, resulting in an overall positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are few examples:\n",
    "1. Sentence: 'The customer service was excellent, and I received my order quickly.'\n",
    "Sentiment: Positive\n",
    "\n",
    "2. Sentence: 'The food was bland and the service was slow.'\n",
    "Sentiment: Negative\n",
    "\n",
    "3. Sentence: 'The product is okay, but it's not worth the price.'\n",
    "Sentiment: Neutral\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
